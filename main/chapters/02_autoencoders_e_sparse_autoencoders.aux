\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {2}Autoencoders}{2}{section.2}\protected@file@percent }
\newlabel{sec:autoencoders}{{2}{2}{Autoencoders}{section.2}{}}
\newlabel{sec:autoencoders@cref}{{[section][2][]2}{[1][2][]2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Esempi di immagini MNIST $28 \times 28$. Nella riga superiore sono mostrate immagini originali, mentre nella riga inferiore sono riportate versioni contaminate da rumore. La maggior parte delle possibili configurazioni pixel-wise non corrisponde a immagini semanticamente significative.\relax }}{2}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:noisy_images}{{1}{2}{Esempi di immagini MNIST $28 \times 28$. Nella riga superiore sono mostrate immagini originali, mentre nella riga inferiore sono riportate versioni contaminate da rumore. La maggior parte delle possibili configurazioni pixel-wise non corrisponde a immagini semanticamente significative.\relax }{figure.caption.2}{}}
\newlabel{fig:noisy_images@cref}{{[figure][1][]1}{[1][2][]2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Architettura di un autoencoder classico. Il bottleneck forza una compressione informativa che induce l’apprendimento di una rappresentazione latente compatta.\relax }}{3}{figure.caption.3}\protected@file@percent }
\newlabel{fig:autoencoder_arch}{{2}{3}{Architettura di un autoencoder classico. Il bottleneck forza una compressione informativa che induce l’apprendimento di una rappresentazione latente compatta.\relax }{figure.caption.3}{}}
\newlabel{fig:autoencoder_arch@cref}{{[figure][2][]2}{[1][2][]3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Confronto tra immagini originali (riga superiore) e ricostruzioni prodotte dall’autoencoder (riga inferiore). Il modello preserva le strutture principali nonostante la compressione informativa.\relax }}{3}{figure.caption.4}\protected@file@percent }
\newlabel{fig:reconstructions}{{3}{3}{Confronto tra immagini originali (riga superiore) e ricostruzioni prodotte dall’autoencoder (riga inferiore). Il modello preserva le strutture principali nonostante la compressione informativa.\relax }{figure.caption.4}{}}
\newlabel{fig:reconstructions@cref}{{[figure][3][]3}{[1][2][]3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Proiezione bidimensionale dello spazio latente appreso dall’autoencoder. I punti sono colorati in base alla classe MNIST, evidenziando la presenza di cluster semanticamente coerenti.\relax }}{4}{figure.caption.5}\protected@file@percent }
\newlabel{fig:latent_space}{{4}{4}{Proiezione bidimensionale dello spazio latente appreso dall’autoencoder. I punti sono colorati in base alla classe MNIST, evidenziando la presenza di cluster semanticamente coerenti.\relax }{figure.caption.5}{}}
\newlabel{fig:latent_space@cref}{{[figure][4][]4}{[1][2][]4}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Campionamento del decoder su una griglia bidimensionale nello spazio latente. Solo una regione ristretta dello spazio genera immagini semanticamente significative, mentre le restanti producono rumore.\relax }}{5}{figure.caption.6}\protected@file@percent }
\newlabel{fig:latent_manifold}{{5}{5}{Campionamento del decoder su una griglia bidimensionale nello spazio latente. Solo una regione ristretta dello spazio genera immagini semanticamente significative, mentre le restanti producono rumore.\relax }{figure.caption.6}{}}
\newlabel{fig:latent_manifold@cref}{{[figure][5][]5}{[1][2][]5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.0.1}Apprendimento non supervisionato}{6}{subsubsection.2.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.0.2}Encoder, decoder e spazio latente}{6}{subsubsection.2.0.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Schema di funzionamento di un autoencoder \blx@tocontentsinit {0}\parencite {michelucci2022introductionautoencoders}\relax }}{7}{figure.caption.7}\protected@file@percent }
\newlabel{fig:autoencoder}{{6}{7}{Schema di funzionamento di un autoencoder \parencite {michelucci2022introductionautoencoders}\relax }{figure.caption.7}{}}
\newlabel{fig:autoencoder@cref}{{[figure][6][]6}{[1][6][]7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.0.3}Funzione obiettivo e errore di ricostruzione}{7}{subsubsection.2.0.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Il problema dell’identità e la necessità di vincoli}{8}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Bottleneck e riduzione della dimensionalità}{8}{subsubsection.2.1.1}\protected@file@percent }
\newlabel{eq:latent_dim_ae}{{7}{8}{Bottleneck e riduzione della dimensionalità}{equation.2.7}{}}
\newlabel{eq:latent_dim_ae@cref}{{[equation][7][]7}{[1][8][]8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Introduzione di vincoli}{9}{subsubsection.2.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}Relazioni con la PCA}{10}{subsubsection.2.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4}Caso di un autoencoder lineare}{12}{subsubsection.2.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.5}Caso di un autoencoder non lineare}{13}{subsubsection.2.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Interpretabilità delle feature latenti}{14}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Rappresentazioni latenti disentangled}{15}{subsection.2.3}\protected@file@percent }
\newlabel{sec:disentangled_latent}{{2.3}{15}{Rappresentazioni latenti disentangled}{subsection.2.3}{}}
\newlabel{sec:disentangled_latent@cref}{{[subsection][3][2]2.3}{[1][15][]15}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Immagini MNIST generate da InfoGAN con variazioni controllate di cifra, spessore e rotazione. \blx@tocontentsinit {0}\parencite {chen2016infoganinterpretablerepresentationlearning}\relax }}{16}{figure.caption.8}\protected@file@percent }
\newlabel{fig:mnist_disenangled_info_gan}{{7}{16}{Immagini MNIST generate da InfoGAN con variazioni controllate di cifra, spessore e rotazione. \parencite {chen2016infoganinterpretablerepresentationlearning}\relax }{figure.caption.8}{}}
\newlabel{fig:mnist_disenangled_info_gan@cref}{{[figure][7][]7}{[1][15][]16}}
\newlabel{fig:ae_latent_instability}{{8a}{17}{Spazio latente appreso da un autoencoder classico: geometria irregolare e sensibile al training.\relax }{figure.caption.9}{}}
\newlabel{fig:ae_latent_instability@cref}{{[subfigure][1][8]8a}{[1][15][]17}}
\newlabel{sub@fig:ae_latent_instability}{{a}{17}{Spazio latente appreso da un autoencoder classico: geometria irregolare e sensibile al training.\relax }{figure.caption.9}{}}
\newlabel{sub@fig:ae_latent_instability@cref}{{[subfigure][1][8]8a}{[1][15][]17}}
\newlabel{fig:vae_latent_stability}{{8b}{17}{Spazio latente appreso da un Variational Autoencoder: la regolarizzazione verso un prior noto induce una distribuzione più compatta e campionabile.\relax }{figure.caption.9}{}}
\newlabel{fig:vae_latent_stability@cref}{{[subfigure][2][8]8b}{[1][15][]17}}
\newlabel{sub@fig:vae_latent_stability}{{b}{17}{Spazio latente appreso da un Variational Autoencoder: la regolarizzazione verso un prior noto induce una distribuzione più compatta e campionabile.\relax }{figure.caption.9}{}}
\newlabel{sub@fig:vae_latent_stability@cref}{{[subfigure][2][8]8b}{[1][15][]17}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Confronto tra spazi latenti appresi su MNIST. (\subref  {fig:ae_latent_instability}) Autoencoder classico. (\subref  {fig:vae_latent_stability}) Variational Autoencoder. Figure da \blx@tocontentsinit {0}\parencite {gordon2020machine}.\relax }}{17}{figure.caption.9}\protected@file@percent }
\newlabel{fig:ae_vs_vae_latent}{{8}{17}{Confronto tra spazi latenti appresi su MNIST. (\subref {fig:ae_latent_instability}) Autoencoder classico. (\subref {fig:vae_latent_stability}) Variational Autoencoder. Figure da \parencite {gordon2020machine}.\relax }{figure.caption.9}{}}
\newlabel{fig:ae_vs_vae_latent@cref}{{[figure][8][]8}{[1][15][]17}}
\newlabel{eq:beta_vae}{{19}{18}{Rappresentazioni latenti disentangled}{equation.2.19}{}}
\newlabel{eq:beta_vae@cref}{{[equation][19][]19}{[1][16][]18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Sparse Autoencoders}{18}{subsection.2.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Architettura di un autoencoder con dimensionalitàl latente $q \leq n$ \relax }}{19}{figure.caption.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces La figura mostra l'architettura di uno Sparse Autoencoder nel quale la dimensione dello stato latente è maggiore di quella di input.\relax }}{20}{figure.caption.11}\protected@file@percent }
\newlabel{fig:sparse_autoencoder}{{10}{20}{La figura mostra l'architettura di uno Sparse Autoencoder nel quale la dimensione dello stato latente è maggiore di quella di input.\relax }{figure.caption.11}{}}
\newlabel{fig:sparse_autoencoder@cref}{{[figure][10][]10}{[1][18][]20}}
\@setckpt{chapters/02_autoencoders_e_sparse_autoencoders}{
\setcounter{page}{21}
\setcounter{equation}{22}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{section}{2}
\setcounter{subsection}{4}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{10}
\setcounter{table}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{lstnumber}{1}
\setcounter{parentequation}{0}
\setcounter{caption@flags}{0}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{ALG@line}{0}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{tabx@nest}{0}
\setcounter{listtotal}{0}
\setcounter{listcount}{0}
\setcounter{liststart}{0}
\setcounter{liststop}{0}
\setcounter{citecount}{0}
\setcounter{citetotal}{0}
\setcounter{multicitecount}{0}
\setcounter{multicitetotal}{0}
\setcounter{instcount}{11}
\setcounter{maxnames}{1}
\setcounter{minnames}{1}
\setcounter{maxitems}{3}
\setcounter{minitems}{1}
\setcounter{citecounter}{0}
\setcounter{maxcitecounter}{0}
\setcounter{savedcitecounter}{0}
\setcounter{uniquelist}{0}
\setcounter{uniquename}{0}
\setcounter{refsection}{0}
\setcounter{refsegment}{0}
\setcounter{maxextratitle}{0}
\setcounter{maxextratitleyear}{0}
\setcounter{maxextraname}{0}
\setcounter{maxextradate}{0}
\setcounter{maxextraalpha}{0}
\setcounter{abbrvpenalty}{50}
\setcounter{highnamepenalty}{50}
\setcounter{lownamepenalty}{25}
\setcounter{maxparens}{3}
\setcounter{parenlevel}{0}
\setcounter{blx@maxsection}{0}
\setcounter{blx@maxsegment@0}{0}
\setcounter{blx@sectionciteorder@0}{11}
\setcounter{mincomprange}{10}
\setcounter{maxcomprange}{100000}
\setcounter{mincompwidth}{1}
\setcounter{afterword}{0}
\setcounter{savedafterword}{0}
\setcounter{annotator}{0}
\setcounter{savedannotator}{0}
\setcounter{author}{0}
\setcounter{savedauthor}{0}
\setcounter{bookauthor}{0}
\setcounter{savedbookauthor}{0}
\setcounter{commentator}{0}
\setcounter{savedcommentator}{0}
\setcounter{editor}{0}
\setcounter{savededitor}{0}
\setcounter{editora}{0}
\setcounter{savededitora}{0}
\setcounter{editorb}{0}
\setcounter{savededitorb}{0}
\setcounter{editorc}{0}
\setcounter{savededitorc}{0}
\setcounter{foreword}{0}
\setcounter{savedforeword}{0}
\setcounter{holder}{0}
\setcounter{savedholder}{0}
\setcounter{introduction}{0}
\setcounter{savedintroduction}{0}
\setcounter{namea}{0}
\setcounter{savednamea}{0}
\setcounter{nameb}{0}
\setcounter{savednameb}{0}
\setcounter{namec}{0}
\setcounter{savednamec}{0}
\setcounter{translator}{0}
\setcounter{savedtranslator}{0}
\setcounter{shortauthor}{0}
\setcounter{savedshortauthor}{0}
\setcounter{shorteditor}{0}
\setcounter{savedshorteditor}{0}
\setcounter{labelname}{0}
\setcounter{savedlabelname}{0}
\setcounter{institution}{0}
\setcounter{savedinstitution}{0}
\setcounter{lista}{0}
\setcounter{savedlista}{0}
\setcounter{listb}{0}
\setcounter{savedlistb}{0}
\setcounter{listc}{0}
\setcounter{savedlistc}{0}
\setcounter{listd}{0}
\setcounter{savedlistd}{0}
\setcounter{liste}{0}
\setcounter{savedliste}{0}
\setcounter{listf}{0}
\setcounter{savedlistf}{0}
\setcounter{location}{0}
\setcounter{savedlocation}{0}
\setcounter{organization}{0}
\setcounter{savedorganization}{0}
\setcounter{origlocation}{0}
\setcounter{savedoriglocation}{0}
\setcounter{origpublisher}{0}
\setcounter{savedorigpublisher}{0}
\setcounter{publisher}{0}
\setcounter{savedpublisher}{0}
\setcounter{language}{0}
\setcounter{savedlanguage}{0}
\setcounter{origlanguage}{0}
\setcounter{savedoriglanguage}{0}
\setcounter{pageref}{0}
\setcounter{savedpageref}{0}
\setcounter{textcitecount}{0}
\setcounter{textcitetotal}{0}
\setcounter{textcitemaxnames}{0}
\setcounter{biburlbigbreakpenalty}{100}
\setcounter{biburlbreakpenalty}{200}
\setcounter{biburlnumpenalty}{0}
\setcounter{biburlucpenalty}{0}
\setcounter{biburllcpenalty}{0}
\setcounter{smartand}{1}
\setcounter{bbx:relatedcount}{0}
\setcounter{bbx:relatedtotal}{0}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{14}
\setcounter{FancyVerbLine}{0}
\setcounter{tcbbreakpart}{1}
\setcounter{tcblayer}{0}
\setcounter{tcolorbox@number}{3}
\setcounter{definition}{0}
\setcounter{lstlisting}{0}
\setcounter{section@level}{2}
}

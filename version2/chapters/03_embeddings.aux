\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Embeddings}{17}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Introduzione}{18}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}L'ipotesi distribuzionale}{18}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Ipotesi di Osgood}{19}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Embeddings}{20}{section.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Simple count-based embeddings}{20}{subsection.3.4.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Esempio di matrice di co-occorrenza con finestra di contesto di ampiezza 1.\relax }}{20}{table.caption.6}\protected@file@percent }
\newlabel{table:davies2015wikipedia}{{\caption@xref {table:davies2015wikipedia}{ on input line 152}}{21}{Simple count-based embeddings}{table.caption.7}{}}
\newlabel{table:davies2015wikipedia@cref}{{[subsection][1][3,4]3.4.1}{[1][21][]21}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Estratto reale della matrice word-context calcolata sul corpus Wikipedia, \blx@tocontentsinit {0}\cite {davies2015wikipedia}\relax }}{21}{table.caption.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Estratto reale di vettori di co-occorrenza calcolati sul corpus Wikipedia (mostra solo alcune dimensioni del vettore).\relax }}{21}{figure.caption.8}\protected@file@percent }
\newlabel{fig:jurafsky53}{{3.1}{21}{Estratto reale di vettori di co-occorrenza calcolati sul corpus Wikipedia (mostra solo alcune dimensioni del vettore).\relax }{figure.caption.8}{}}
\newlabel{fig:jurafsky53@cref}{{[figure][1][3]3.1}{[1][21][]21}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Riduzione dimensionale tramite SVD}{22}{subsection.3.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Cosine Similarity}{23}{subsection.3.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Word2Vec}{24}{subsection.3.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Il classificatore}{25}{section*.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Lo skip-gram apprende in totale due insiemi di embedding, uno per i target e uno per i contesti, per un totale di $2|V|$ vettori, ciascuno di dimensione $d$. L’addestramento del modello ha quindi un unico scopo: apprendere questi vettori in modo da massimizzare la probabilità che le parole realmente vicine nel testo risultino simili nei loro embedding\relax }}{28}{figure.caption.14}\protected@file@percent }
\newlabel{fig:skipgram_structure}{{3.2}{28}{Lo skip-gram apprende in totale due insiemi di embedding, uno per i target e uno per i contesti, per un totale di $2|V|$ vettori, ciascuno di dimensione $d$. L’addestramento del modello ha quindi un unico scopo: apprendere questi vettori in modo da massimizzare la probabilità che le parole realmente vicine nel testo risultino simili nei loro embedding\relax }{figure.caption.14}{}}
\newlabel{fig:skipgram_structure@cref}{{[figure][2][3]3.2}{[1][27][]28}}
\@writefile{toc}{\contentsline {subsubsection}{Esempio delle matrici $W$ e $C$}{28}{section*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Algoritmo di apprendimento}{29}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.5}Proprietà semantiche degli embeddings}{31}{subsection.3.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{1. Influenza della finestra di contesto}{31}{section*.17}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{2. First-order vs. second-order similarity}{31}{section*.18}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{3. Analogical reasoning (modello del parallelogramma)}{31}{section*.19}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{4. Struttura geometrica: ortogonalità e parallelismo}{32}{section*.20}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{5. Effetti pratici}{32}{section*.21}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Contextual Embeddings}{33}{section.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Modelli di linguaggio neurali}{34}{section.3.6}\protected@file@percent }
\newlabel{sec:neural_language_models}{{3.6}{34}{Modelli di linguaggio neurali}{section.3.6}{}}
\newlabel{sec:neural_language_models@cref}{{[section][6][3]3.6}{[1][34][]34}}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Reti neurali ricorrenti e LSTM}{36}{section.3.7}\protected@file@percent }
\newlabel{sec:rnn_lstm}{{3.7}{36}{Reti neurali ricorrenti e LSTM}{section.3.7}{}}
\newlabel{sec:rnn_lstm@cref}{{[section][7][3]3.7}{[1][36][]36}}
\@writefile{toc}{\contentsline {section}{\numberline {3.8}ELMo e il contesto bidirezionale}{38}{section.3.8}\protected@file@percent }
\newlabel{sec:elmo}{{3.8}{38}{ELMo e il contesto bidirezionale}{section.3.8}{}}
\newlabel{sec:elmo@cref}{{[section][8][3]3.8}{[1][37][]38}}
\@writefile{toc}{\contentsline {section}{\numberline {3.9}Attention e Self-Attention}{39}{section.3.9}\protected@file@percent }
\newlabel{sec:attention}{{3.9}{39}{Attention e Self-Attention}{section.3.9}{}}
\newlabel{sec:attention@cref}{{[section][9][3]3.9}{[1][39][]39}}
\@writefile{toc}{\contentsline {section}{\numberline {3.10}BERT e Masked Language Modeling}{40}{section.3.10}\protected@file@percent }
\newlabel{sec:bert}{{3.10}{40}{BERT e Masked Language Modeling}{section.3.10}{}}
\newlabel{sec:bert@cref}{{[section][10][3]3.10}{[1][40][]40}}
\@writefile{toc}{\contentsline {section}{\numberline {3.11}Motivazione per il disentanglement degli embeddings di BERT}{42}{section.3.11}\protected@file@percent }
\newlabel{sec:motivation_disentanglement}{{3.11}{42}{Motivazione per il disentanglement degli embeddings di BERT}{section.3.11}{}}
\newlabel{sec:motivation_disentanglement@cref}{{[section][11][3]3.11}{[1][42][]42}}
\@setckpt{chapters/03_embeddings}{
\setcounter{page}{44}
\setcounter{equation}{3}
\setcounter{enumi}{4}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{3}
\setcounter{section}{11}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{2}
\setcounter{table}{2}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{lstnumber}{1}
\setcounter{parentequation}{0}
\setcounter{tabx@nest}{0}
\setcounter{listtotal}{0}
\setcounter{listcount}{0}
\setcounter{liststart}{0}
\setcounter{liststop}{0}
\setcounter{citecount}{0}
\setcounter{citetotal}{0}
\setcounter{multicitecount}{0}
\setcounter{multicitetotal}{0}
\setcounter{instcount}{8}
\setcounter{maxnames}{3}
\setcounter{minnames}{1}
\setcounter{maxitems}{3}
\setcounter{minitems}{1}
\setcounter{citecounter}{0}
\setcounter{maxcitecounter}{0}
\setcounter{savedcitecounter}{0}
\setcounter{uniquelist}{0}
\setcounter{uniquename}{0}
\setcounter{refsection}{0}
\setcounter{refsegment}{0}
\setcounter{maxextratitle}{0}
\setcounter{maxextratitleyear}{0}
\setcounter{maxextraname}{0}
\setcounter{maxextradate}{0}
\setcounter{maxextraalpha}{0}
\setcounter{abbrvpenalty}{50}
\setcounter{highnamepenalty}{50}
\setcounter{lownamepenalty}{25}
\setcounter{maxparens}{3}
\setcounter{parenlevel}{0}
\setcounter{blx@maxsection}{0}
\setcounter{blx@maxsegment@0}{0}
\setcounter{blx@sectionciteorder@0}{8}
\setcounter{mincomprange}{10}
\setcounter{maxcomprange}{100000}
\setcounter{mincompwidth}{1}
\setcounter{afterword}{0}
\setcounter{savedafterword}{0}
\setcounter{annotator}{0}
\setcounter{savedannotator}{0}
\setcounter{author}{0}
\setcounter{savedauthor}{0}
\setcounter{bookauthor}{0}
\setcounter{savedbookauthor}{0}
\setcounter{commentator}{0}
\setcounter{savedcommentator}{0}
\setcounter{editor}{0}
\setcounter{savededitor}{0}
\setcounter{editora}{0}
\setcounter{savededitora}{0}
\setcounter{editorb}{0}
\setcounter{savededitorb}{0}
\setcounter{editorc}{0}
\setcounter{savededitorc}{0}
\setcounter{foreword}{0}
\setcounter{savedforeword}{0}
\setcounter{holder}{0}
\setcounter{savedholder}{0}
\setcounter{introduction}{0}
\setcounter{savedintroduction}{0}
\setcounter{namea}{0}
\setcounter{savednamea}{0}
\setcounter{nameb}{0}
\setcounter{savednameb}{0}
\setcounter{namec}{0}
\setcounter{savednamec}{0}
\setcounter{translator}{0}
\setcounter{savedtranslator}{0}
\setcounter{shortauthor}{0}
\setcounter{savedshortauthor}{0}
\setcounter{shorteditor}{0}
\setcounter{savedshorteditor}{0}
\setcounter{labelname}{0}
\setcounter{savedlabelname}{0}
\setcounter{institution}{0}
\setcounter{savedinstitution}{0}
\setcounter{lista}{0}
\setcounter{savedlista}{0}
\setcounter{listb}{0}
\setcounter{savedlistb}{0}
\setcounter{listc}{0}
\setcounter{savedlistc}{0}
\setcounter{listd}{0}
\setcounter{savedlistd}{0}
\setcounter{liste}{0}
\setcounter{savedliste}{0}
\setcounter{listf}{0}
\setcounter{savedlistf}{0}
\setcounter{location}{0}
\setcounter{savedlocation}{0}
\setcounter{organization}{0}
\setcounter{savedorganization}{0}
\setcounter{origlocation}{0}
\setcounter{savedoriglocation}{0}
\setcounter{origpublisher}{0}
\setcounter{savedorigpublisher}{0}
\setcounter{publisher}{0}
\setcounter{savedpublisher}{0}
\setcounter{language}{0}
\setcounter{savedlanguage}{0}
\setcounter{origlanguage}{0}
\setcounter{savedoriglanguage}{0}
\setcounter{pageref}{0}
\setcounter{savedpageref}{0}
\setcounter{textcitecount}{0}
\setcounter{textcitetotal}{0}
\setcounter{textcitemaxnames}{0}
\setcounter{biburlbigbreakpenalty}{100}
\setcounter{biburlbreakpenalty}{200}
\setcounter{biburlnumpenalty}{0}
\setcounter{biburlucpenalty}{0}
\setcounter{biburllcpenalty}{0}
\setcounter{smartand}{1}
\setcounter{bbx:relatedcount}{0}
\setcounter{bbx:relatedtotal}{0}
\setcounter{Item}{15}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{32}
\setcounter{FancyVerbLine}{0}
\setcounter{caption@flags}{0}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{tcbbreakpart}{1}
\setcounter{tcblayer}{0}
\setcounter{tcolorbox@number}{8}
\setcounter{definition}{0}
\setcounter{lstlisting}{0}
\setcounter{section@level}{1}
}

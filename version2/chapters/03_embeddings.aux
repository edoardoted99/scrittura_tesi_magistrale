\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Embeddings}{17}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Introduzione}{18}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}L'ipotesi distribuzionale}{18}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Ipotesi di Osgood}{19}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Embeddings}{20}{section.3.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Classificazione delle principali tipologie di embeddings trattate nel capitolo.\relax }}{21}{figure.caption.7}\protected@file@percent }
\newlabel{fig:classificazione_embeddings}{{3.1}{21}{Classificazione delle principali tipologie di embeddings trattate nel capitolo.\relax }{figure.caption.7}{}}
\newlabel{fig:classificazione_embeddings@cref}{{[figure][1][3]3.1}{[1][20][]21}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Embeddings count-based}{21}{subsection.3.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Matrice termine-documento}{21}{section*.8}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Term-document matrix per quattro parole in quattro opere di Shakespeare. Ogni cella contiene il numero di occorrenze della parola (riga) nel documento (colonna). \blx@tocontentsinit {0}\cite {wang2024disentangledrepresentationlearning}\relax }}{22}{table.caption.9}\protected@file@percent }
\newlabel{tab:term_document_shakespeare}{{3.1}{22}{Term-document matrix per quattro parole in quattro opere di Shakespeare. Ogni cella contiene il numero di occorrenze della parola (riga) nel documento (colonna). \cite {wang2024disentangledrepresentationlearning}\relax }{table.caption.9}{}}
\newlabel{tab:term_document_shakespeare@cref}{{[table][1][3]3.1}{[1][21][]22}}
\@writefile{toc}{\contentsline {subsubsection}{Matrice termine-termine}{22}{section*.10}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Estratto di una matrice termine--termine calcolata sul corpus Wikipedia. Ogni cella contiene il numero di co-occorrenze tra la parola target (riga) e la parola di contesto (colonna) all’interno di una finestra di contesto locale \blx@tocontentsinit {0}\cite {wang2024disentangledrepresentationlearning}.\relax }}{23}{table.caption.11}\protected@file@percent }
\newlabel{tab:term_term_wikipedia}{{3.2}{23}{Estratto di una matrice termine--termine calcolata sul corpus Wikipedia. Ogni cella contiene il numero di co-occorrenze tra la parola target (riga) e la parola di contesto (colonna) all’interno di una finestra di contesto locale \cite {wang2024disentangledrepresentationlearning}.\relax }{table.caption.11}{}}
\newlabel{tab:term_term_wikipedia@cref}{{[table][2][3]3.2}{[1][23][]23}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Riduzione dimensionale tramite SVD}{24}{subsection.3.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Cosine Similarity}{25}{subsection.3.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Word2Vec: un approccio predittivo}{26}{subsection.3.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Il classificatore e la funzione sigmoide}{26}{section*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Apprendimento e Negative Sampling}{27}{section*.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Perché due matrici? Il ruolo di $W$ e $C$}{27}{section*.14}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Lo skip-gram apprende in totale due insiemi di embedding, uno per i target ($W$) e uno per i contesti ($C$), per un totale di $2|V|$ vettori. L’addestramento mira a massimizzare la probabilità che parole vicine nel testo abbiano vettori simili.\relax }}{28}{figure.caption.15}\protected@file@percent }
\newlabel{fig:skipgram_structure}{{3.2}{28}{Lo skip-gram apprende in totale due insiemi di embedding, uno per i target ($W$) e uno per i contesti ($C$), per un totale di $2|V|$ vettori. L’addestramento mira a massimizzare la probabilità che parole vicine nel testo abbiano vettori simili.\relax }{figure.caption.15}{}}
\newlabel{fig:skipgram_structure@cref}{{[figure][2][3]3.2}{[1][28][]28}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.5}Proprietà semantiche degli embeddings}{28}{subsection.3.4.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Rappresentazione geometrica del modello del parallelogramma applicato all'analogia di genere.\relax }}{29}{figure.caption.16}\protected@file@percent }
\newlabel{fig:parallelogramma}{{3.3}{29}{Rappresentazione geometrica del modello del parallelogramma applicato all'analogia di genere.\relax }{figure.caption.16}{}}
\newlabel{fig:parallelogramma@cref}{{[figure][3][3]3.3}{[1][29][]29}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Contextual Embeddings}{30}{section.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Modelli di linguaggio neurali}{31}{section.3.6}\protected@file@percent }
\newlabel{sec:neural_language_models}{{3.6}{31}{Modelli di linguaggio neurali}{section.3.6}{}}
\newlabel{sec:neural_language_models@cref}{{[section][6][3]3.6}{[1][31][]31}}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Reti neurali ricorrenti e LSTM}{33}{section.3.7}\protected@file@percent }
\newlabel{sec:rnn_lstm}{{3.7}{33}{Reti neurali ricorrenti e LSTM}{section.3.7}{}}
\newlabel{sec:rnn_lstm@cref}{{[section][7][3]3.7}{[1][33][]33}}
\@writefile{toc}{\contentsline {section}{\numberline {3.8}ELMo e il contesto bidirezionale}{35}{section.3.8}\protected@file@percent }
\newlabel{sec:elmo}{{3.8}{35}{ELMo e il contesto bidirezionale}{section.3.8}{}}
\newlabel{sec:elmo@cref}{{[section][8][3]3.8}{[1][35][]35}}
\@writefile{toc}{\contentsline {section}{\numberline {3.9}Attention e Self-Attention}{36}{section.3.9}\protected@file@percent }
\newlabel{sec:attention}{{3.9}{36}{Attention e Self-Attention}{section.3.9}{}}
\newlabel{sec:attention@cref}{{[section][9][3]3.9}{[1][36][]36}}
\@writefile{toc}{\contentsline {section}{\numberline {3.10}BERT e Masked Language Modeling}{38}{section.3.10}\protected@file@percent }
\newlabel{sec:bert}{{3.10}{38}{BERT e Masked Language Modeling}{section.3.10}{}}
\newlabel{sec:bert@cref}{{[section][10][3]3.10}{[1][37][]38}}
\@writefile{toc}{\contentsline {section}{\numberline {3.11}Motivazione per il disentanglement degli embeddings di BERT}{39}{section.3.11}\protected@file@percent }
\newlabel{sec:motivation_disentanglement}{{3.11}{39}{Motivazione per il disentanglement degli embeddings di BERT}{section.3.11}{}}
\newlabel{sec:motivation_disentanglement@cref}{{[section][11][3]3.11}{[1][39][]39}}
\@writefile{toc}{\contentsline {section}{\numberline {3.12}Pooling}{41}{section.3.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Strategie di pooling}{42}{section*.18}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.12.1}Pooling gerarchico per sequenze lunghe}{43}{subsection.3.12.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Segmentazione in chunk}{43}{section*.19}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Pooling a livello di token (intra-chunk)}{44}{section*.20}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Pooling a livello di chunk (inter-chunk)}{44}{section*.21}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Interpretazione come pooling gerarchico}{44}{section*.22}\protected@file@percent }
\@setckpt{chapters/03_embeddings}{
\setcounter{page}{45}
\setcounter{equation}{5}
\setcounter{enumi}{2}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{3}
\setcounter{section}{12}
\setcounter{subsection}{1}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{3}
\setcounter{table}{2}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{lstnumber}{1}
\setcounter{parentequation}{0}
\setcounter{tabx@nest}{0}
\setcounter{listtotal}{0}
\setcounter{listcount}{0}
\setcounter{liststart}{0}
\setcounter{liststop}{0}
\setcounter{citecount}{0}
\setcounter{citetotal}{0}
\setcounter{multicitecount}{0}
\setcounter{multicitetotal}{0}
\setcounter{instcount}{11}
\setcounter{maxnames}{3}
\setcounter{minnames}{1}
\setcounter{maxitems}{3}
\setcounter{minitems}{1}
\setcounter{citecounter}{0}
\setcounter{maxcitecounter}{0}
\setcounter{savedcitecounter}{0}
\setcounter{uniquelist}{0}
\setcounter{uniquename}{0}
\setcounter{refsection}{0}
\setcounter{refsegment}{0}
\setcounter{maxextratitle}{0}
\setcounter{maxextratitleyear}{0}
\setcounter{maxextraname}{0}
\setcounter{maxextradate}{0}
\setcounter{maxextraalpha}{0}
\setcounter{abbrvpenalty}{50}
\setcounter{highnamepenalty}{50}
\setcounter{lownamepenalty}{25}
\setcounter{maxparens}{3}
\setcounter{parenlevel}{0}
\setcounter{blx@maxsection}{0}
\setcounter{blx@maxsegment@0}{0}
\setcounter{blx@sectionciteorder@0}{11}
\setcounter{mincomprange}{10}
\setcounter{maxcomprange}{100000}
\setcounter{mincompwidth}{1}
\setcounter{afterword}{0}
\setcounter{savedafterword}{0}
\setcounter{annotator}{0}
\setcounter{savedannotator}{0}
\setcounter{author}{0}
\setcounter{savedauthor}{0}
\setcounter{bookauthor}{0}
\setcounter{savedbookauthor}{0}
\setcounter{commentator}{0}
\setcounter{savedcommentator}{0}
\setcounter{editor}{0}
\setcounter{savededitor}{0}
\setcounter{editora}{0}
\setcounter{savededitora}{0}
\setcounter{editorb}{0}
\setcounter{savededitorb}{0}
\setcounter{editorc}{0}
\setcounter{savededitorc}{0}
\setcounter{foreword}{0}
\setcounter{savedforeword}{0}
\setcounter{holder}{0}
\setcounter{savedholder}{0}
\setcounter{introduction}{0}
\setcounter{savedintroduction}{0}
\setcounter{namea}{0}
\setcounter{savednamea}{0}
\setcounter{nameb}{0}
\setcounter{savednameb}{0}
\setcounter{namec}{0}
\setcounter{savednamec}{0}
\setcounter{translator}{0}
\setcounter{savedtranslator}{0}
\setcounter{shortauthor}{0}
\setcounter{savedshortauthor}{0}
\setcounter{shorteditor}{0}
\setcounter{savedshorteditor}{0}
\setcounter{labelname}{0}
\setcounter{savedlabelname}{0}
\setcounter{institution}{0}
\setcounter{savedinstitution}{0}
\setcounter{lista}{0}
\setcounter{savedlista}{0}
\setcounter{listb}{0}
\setcounter{savedlistb}{0}
\setcounter{listc}{0}
\setcounter{savedlistc}{0}
\setcounter{listd}{0}
\setcounter{savedlistd}{0}
\setcounter{liste}{0}
\setcounter{savedliste}{0}
\setcounter{listf}{0}
\setcounter{savedlistf}{0}
\setcounter{location}{0}
\setcounter{savedlocation}{0}
\setcounter{organization}{0}
\setcounter{savedorganization}{0}
\setcounter{origlocation}{0}
\setcounter{savedoriglocation}{0}
\setcounter{origpublisher}{0}
\setcounter{savedorigpublisher}{0}
\setcounter{publisher}{0}
\setcounter{savedpublisher}{0}
\setcounter{language}{0}
\setcounter{savedlanguage}{0}
\setcounter{origlanguage}{0}
\setcounter{savedoriglanguage}{0}
\setcounter{pageref}{0}
\setcounter{savedpageref}{0}
\setcounter{textcitecount}{0}
\setcounter{textcitetotal}{0}
\setcounter{textcitemaxnames}{0}
\setcounter{biburlbigbreakpenalty}{100}
\setcounter{biburlbreakpenalty}{200}
\setcounter{biburlnumpenalty}{0}
\setcounter{biburlucpenalty}{0}
\setcounter{biburllcpenalty}{0}
\setcounter{smartand}{1}
\setcounter{bbx:relatedcount}{0}
\setcounter{bbx:relatedtotal}{0}
\setcounter{Item}{11}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{34}
\setcounter{FancyVerbLine}{0}
\setcounter{caption@flags}{0}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{tcbbreakpart}{1}
\setcounter{tcblayer}{0}
\setcounter{tcolorbox@number}{12}
\setcounter{definition}{0}
\setcounter{lstlisting}{0}
\setcounter{section@level}{4}
}

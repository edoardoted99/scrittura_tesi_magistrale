\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand{\transparent@use}[1]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@refcontext{nyt/global//global/global}
\abx@aux@cite{0}{devlin2018bert}
\abx@aux@segm{0}{0}{devlin2018bert}
\abx@aux@cite{0}{wang2024disentangledrepresentationlearning}
\abx@aux@segm{0}{0}{wang2024disentangledrepresentationlearning}
\abx@aux@cite{0}{elhage2022toy}
\abx@aux@segm{0}{0}{elhage2022toy}
\abx@aux@cite{0}{elhage2022toy}
\abx@aux@segm{0}{0}{elhage2022toy}
\abx@aux@cite{0}{oneill2024disentangling}
\abx@aux@segm{0}{0}{oneill2024disentangling}
\abx@aux@cite{0}{oneill2024disentangling}
\abx@aux@segm{0}{0}{oneill2024disentangling}
\abx@aux@cite{0}{oneill2024disentangling}
\abx@aux@segm{0}{0}{oneill2024disentangling}
\babel@aux{italian}{}
\babel@aux{italian}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduzione e Problema}{1}{section.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Home page di PRISMA. Applicazione sviluppata in tesi con lo scopo di costruire rappresentaizioni latenti interpretabili per i large language models}}{1}{figure.1}\protected@file@percent }
\newlabel{fig:home_prisa}{{1}{1}{Home page di PRISMA. Applicazione sviluppata in tesi con lo scopo di costruire rappresentaizioni latenti interpretabili per i large language models}{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}PRISMA}{1}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Autoencoders Classici}{1}{subsection.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Architettura di un Autoencoder classico: il bottleneck forza la compressione informativa.}}{1}{figure.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Analisi della semantica nell'AE. A destra: lo spazio latente mostra cluster isolati (vincoli imposti dai dati). A sinistra: le generazioni mostrano che nelle zone vuote tra i cluster, dove mancano i vincoli, la semantica scompare lasciando spazio a ricostruzioni incoerenti.}}{1}{figure.3}\protected@file@percent }
\newlabel{fig:ae_no_semantics}{{3}{1}{Analisi della semantica nell'AE. A destra: lo spazio latente mostra cluster isolati (vincoli imposti dai dati). A sinistra: le generazioni mostrano che nelle zone vuote tra i cluster, dove mancano i vincoli, la semantica scompare lasciando spazio a ricostruzioni incoerenti}{figure.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Sparse Autoencoders (SAE)}{1}{subsection.2.2}\protected@file@percent }
\abx@aux@cite{0}{oneill2024disentangling}
\abx@aux@segm{0}{0}{oneill2024disentangling}
\abx@aux@cite{0}{oneill2024disentangling}
\abx@aux@segm{0}{0}{oneill2024disentangling}
\abx@aux@cite{0}{elhage2022toy}
\abx@aux@segm{0}{0}{elhage2022toy}
\abx@aux@cite{0}{oneill2024disentangling}
\abx@aux@segm{0}{0}{oneill2024disentangling}
\abx@aux@cite{0}{oneill2024disentangling}
\abx@aux@segm{0}{0}{oneill2024disentangling}
\abx@aux@cite{0}{oneill2024disentangling}
\abx@aux@segm{0}{0}{oneill2024disentangling}
\abx@aux@cite{0}{oneill2024disentangling}
\abx@aux@segm{0}{0}{oneill2024disentangling}
\abx@aux@cite{0}{oneill2024disentangling}
\abx@aux@segm{0}{0}{oneill2024disentangling}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Sparse Autoencoder: spazio latente overcomplete con attivazioni sparse.}}{2}{figure.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Architettura}{2}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Training e Loss Function}{2}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}Vincolo di Sparsità (Top-K / k-sparse)}{2}{subsubsection.2.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}Auxiliary Loss (AuxK, ispirata ai Ghost Grads)}{2}{subsubsection.2.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Rappresentazione Latente}{2}{subsection.2.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Visualizzazione della matrice sparsa $H$ (primi 500 neuroni). Le attivazioni sono puntiformi e verticali.}}{2}{figure.5}\protected@file@percent }
\newlabel{fig:latent_h}{{5}{2}{Visualizzazione della matrice sparsa $H$ (primi 500 neuroni). Le attivazioni sono puntiformi e verticali}{figure.5}{}}
\abx@aux@cite{0}{oneill2024disentangling}
\abx@aux@segm{0}{0}{oneill2024disentangling}
\abx@aux@cite{0}{oneill2024disentangling}
\abx@aux@segm{0}{0}{oneill2024disentangling}
\abx@aux@cite{0}{roy2007effective}
\abx@aux@segm{0}{0}{roy2007effective}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Interpretabilità degli assi}{3}{subsection.2.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Processo di training e feature labelling del SAE: interpretazione delle feature tramite LLM \blx@tocontentsinit {0}\parencite {oneill2024disentangling}.}}{3}{figure.6}\protected@file@percent }
\newlabel{fig:architecture}{{6}{3}{Processo di training e feature labelling del SAE: interpretazione delle feature tramite LLM \parencite {oneill2024disentangling}}{figure.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Analisi della Dimensionalità: Effective Rank}{3}{section.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Effective Rank vs expansion factor (real vs ipotesi nulla) e Semantic Compression Ratio (SCR\%).}}{3}{figure.7}\protected@file@percent }
\newlabel{fig:erank_scr}{{7}{3}{Effective Rank vs expansion factor (real vs ipotesi nulla) e Semantic Compression Ratio (SCR\%)}{figure.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusioni}{3}{section.4}\protected@file@percent }
\abx@aux@read@bbl@mdfivesum{nohash}
\abx@aux@read@bblrerun
\gdef \@abspage@last{3}

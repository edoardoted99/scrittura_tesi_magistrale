
\chapter{Introduzione}
\section{Introduzione}

% -------------------------------------------------
% 1.1 Contesto generale
% -------------------------------------------------
Negli ultimi anni, i \textit{Large Language Models} (LLM) hanno rappresentato un punto di svolta nel campo del \textit{Natural Language Processing} (NLP).
Questi modelli, basati sull’architettura \textit{Transformer}, hanno raggiunto risultati senza precedenti in una vasta gamma di compiti linguistici, come la traduzione automatica, la generazione di testo e la comprensione semantica.

L’interesse verso gli LLM non deriva solo dalle loro prestazioni tecniche, ma anche dalle implicazioni economiche, etiche e sociali che ne derivano.
Oggi, modelli come GPT, LLaMA, PaLM e Claude alimentano sistemi di intelligenza artificiale conversazionale e strumenti di supporto scientifico, didattico e creativo.

% -------------------------------------------------
% 1.2 Motivazioni
% -------------------------------------------------
\subsection{Motivazioni}

La crescente adozione degli LLM nei contesti accademici e industriali richiede una comprensione profonda delle loro architetture e dei processi di addestramento.
Comprendere come questi modelli apprendono, generalizzano e talvolta falliscono è essenziale per garantire un uso responsabile e consapevole dell’IA.

Questa tesi nasce dall’esigenza di:
\begin{itemize}
    \item analizzare le basi teoriche e pratiche che rendono gli LLM così efficaci;
    \item valutare le principali tecniche di ottimizzazione e allineamento;
    \item discutere i limiti, i bias e i rischi connessi al loro impiego.
\end{itemize}

% -------------------------------------------------
% 1.3 Obiettivi e struttura della tesi
% -------------------------------------------------
\subsection{Obiettivi e struttura della tesi}

L’obiettivo generale di questa tesi è esplorare i principi alla base dei Large Language Models, discutendo il loro funzionamento interno, le tecniche di addestramento e le implicazioni derivanti dal loro utilizzo.

La tesi è strutturata come segue:
\begin{itemize}
    \item \textbf{Capitolo 2} – Descrive le basi teoriche e l’architettura \textit{Transformer}, cuore degli LLM moderni.
    \item \textbf{Capitolo 3} – Presenta il processo di \textit{pre-training}, \textit{fine-tuning} e \textit{reinforcement learning from human feedback} (RLHF).
    \item \textbf{Capitolo 4} – Analizza i risultati ottenuti e le metriche di valutazione.
    \item \textbf{Capitolo 5} – Discute le implicazioni etiche, i rischi e le prospettive future dell’uso degli LLM.
    \item \textbf{Capitolo 6} – Riassume le conclusioni e propone possibili sviluppi futuri.
\end{itemize}

\vspace{1em}
In sintesi, questa tesi intende offrire una panoramica completa degli LLM, integrando l’aspetto tecnico con una riflessione critica sul loro impatto nella società contemporanea.
